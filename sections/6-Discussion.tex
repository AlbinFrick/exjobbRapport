\section{Discussion}
% Discussion about the results and why it turned out the way it did. Hopefully this created a great tool that will take over the world

In this section, a discussion about the results of the study will be taken place. Furthermore, a discussion on what could have been done differently. What was done well, and what could have been improved for all the stages of the study. The prototype that was produced, the usability, and the A/B testing that unfortunately could not be executed.


\subsection{The Prototype}%
\label{sub:The Prototype}
Most time and effort for this project went into creating the prototype. 
There were a lot of problems that needed to be solved where the biggest one was; How can a component be built that works for all JavaScript frameworks, including static pages. The research focused on finding solutions that made it possible to work with static pages. Because if a solution that works natively within HTML-CSS-JavaScript has a much higher chance of working together with frameworks. The web component was a clear choice.

As explained in the theory section, Web components are a mixture of three technologies, custom elements, shadow DOM, and HTML templates. This would work natively for all frameworks and static pages. The problem with using web components is that it is complicated to make the components loosely coupled between projects. The LitElement class from Polymer provided a solution. In addition, this also made the creation of the components much more straightforward. A problem with LitElement was that to use them \textit{open imports} need to be handled. This is when the import does not target a file or a function from a module. This is only supported when running in node.js, not in browsers at the moment. To solve this issue, a bundler must be used, such as Webpack or Rollup. This was not optimal, but the upside of LitElement still transcends this downside. This answers two of the research questions stated at the beginning of the project:
\begin{itemize}
  \item \textit{Can components be built that works for all JavaScript frameworks and static pages?} 
  \item \textit{Is it possible to automate the whole process from UI design program to browser runnable code?}.
\end{itemize}

One of the biggest struggles with creating the tool was to make sure that the prototype built the right amount of elements in the right place. This was solved with recursive functions. These functions call themself until they handle the ''youngest'' child and build the elements from there and go from generation to generation. This is a good way of building the components but it can become a performance taxing function if the components become too big. This has not been tested, but there have been indications of slow performance. Optimizing these functions needs to be carried out to make the prototype viable for more extensive components and projects.

The prototype has some features that, unfortunately, could not be tested within the project timeframe. Such as slotting. Where the user can decide a slot in the component where the user can insert an element or another component into it. This feature was believed to be necessary for carrying out the required task in later tests, which was a wrong assumption. The time spent on developing the feature could have been used for further testing, which would have been more efficient.



\subsection{Interviews}%
\label{sub:Interviews}

The interviews intended to find out how the employees of Knowit work, what their day-to-day routines were. The hope was that the interviews could help shape the prototype into something that felt more familiar to them. There was not as much gathered from the interviews as hoped. Because the new way of making the components with this tool was very new, it was hard to get any similarities with the work they do today. The way of using components and controlling them through properties is something they are working on within some React projects. This was already planned to be done for the components in the prototype but was a good verification. 

The interviews were carried out when the tool had been built for a while. Because of this, some assumptions built up of what the results of the interviews would be. These assumptions were discussed with Knowit, where the majority agreed with prior project experiences. These discussions were held before any interviews took place. The results from the interviews were not discussed with Knowit until all interviews were completed. 

One assumption going into the interviews was that the people working with back-end would be the most excited. This because they would not have to make any adjustments from the front-end with the tool. However, when using the tool, there are more things that the designer has to think about:
\begin{itemize}
  \item How Figma \textit{''sees''} the structure of elements inside the component, not just the visual structure.
  \item Auto-layout needs to be used for all elements in the component for the prototype to work. 
\end{itemize}

Because of this, another assumption for the interviews was that the designers would be more pessimistic about using the tool. 

Both of these assumptions were wrong, and from the interviews, opposite viewpoints were shown. To get a statistical significance, this would require more data points, e.g., too few quantitative data points were collected about how and which opinions were separate between the competence groups.

 The tool forces a more structured design and creates a commonplace where all elements and variables have the same name between competence groups. The majority of the interviewees saw this as something positive. They argued that the tool could increase communication between competence areas. This could result in faster development and a better working environmentâ€”more of this in section \ref{sub:Future Work}.

\subsection{Usability testing}%
\label{sub:Usability testing}
The usability testing in this thesis was done with the more industrial style of working with the resources at hand. The project was carried out over 20 weeks during the Covid 19 pandemic meaning that all testing was done remotely. As a result of this, it was harder to get users to do the tests. All test that was made where a walkthrough for the whole prototype, from design to web component. Smaller tests were considered to check individual parts of the system. This was not used because there were not enough users and time. Because of the broadness of the prototype, it was also crucial that the users could make it from start to finish without any help. 

From the two iterations, seven flaws were found in each iteration. This seems as though the supposedly fixed flaws from the first iteration remained. What is important to note is that the second iteration had added tasks. There were tasks added in the second iteration to maximize the range of the test. The second iteration could confirm the fixes for the flaws in the first iteration and find new flaws in untested features of the system. 

To say that the whole system is user-friendly would be an overstatement since the testing has only been performed on the system's essential functions. The usability tests showed that these essential functions, such as setting up a Figma document and converting its components, are usable and achievable for novice users. The tests also show that altering the components after they have been generated is logical for the users. 

I would argue that this is a very efficient way of building a tool that automates component generation. Thereby answering one of the research questions: \textit{How can a user-friendly tool be built that automates component generation?}



\subsection{A/B testing}%
\label{sub:A/B testing}
Unfortunately, there was no time to do A/B testing. This is still in the study because we found it important that to point out that this could be a good next step. This test was first and foremost supposed to answer the  research question: \textit{Does this tool speed up the development process and if so how much?} With the results from these tests, we could answer this question with statistical significance. This test would be very demanding on finding users but if the results show that it is more efficient to develop with the prototype there is a good incentive to invest in developing it into a real product. 

The test is designed to be performed in pairs of a developer and designer so there was also a hope to get some answers to the research question: \textit{Will automation between design and development increase communication between designers and developers?} This would be done by observing the users during testing. If there is more or less conversation and if the pair find it easier to solve the problem.

\newpage
\section{Conclusion}
\label{sub:conclusion}
This thesis had five research questions.  
\begin{itemize}
  \item Is it possible to automate the whole process from UI design program to browser runnable code? 
 \item Can components be built that works for all JavaScript frameworks and static pages?
  \item How can a user-friendly tool be built that automates component generation?  
  \item Will automation between design and development increase communication between designers and developers?
  \item Does this tool speed up the development process, and if so, how much? 
\end{itemize}

The three first questions could be answered by researching web technologies, creating a prototype that converts Figma components to web components, and ran usability tests on the prototype. The last two research questions did not get answered. However, the thesis supplies steps on how to get these answers through A/B testing. 

The indications from users and interviewees have been positive about what the prototype can do and become a helpful tool for developers and designers. 

\section{Future Work}%
\label{sub:Future Work}

From the interviews and tests that have been performed, there have been many positive indications that the tool could be helpful. The next step for the prototype is either to create a graphical user interface (GUI) or to expand on the functionality of the component generation. The benefits of creating a GUI are that the user does not need to rely on a user guide. It also makes it much easier to handle Figma documents stored in the program. Creating a GUI would take more time, but usability testing would be easier to perform, and the user experience has more potential to be better. It would be easier to steer the user in the right direction. The learning curve for the user could be shortened to be most about using and altering the generated components. 

The tool as of now only supports the most basic styling parameters such as width, height, positioning, etc., but there would not be much work to add more of these. The ones that would be a great addition are gradients, shadows, and rotation because these can become tricky to do manually, especially for more complex components. 

The prototype as of now is highly dependent on the auto-layout feature in Figma. There are possible to work around this and make for a more general solution. This could mean less work for the designer to adapt their design to work with the generator and make development more efficient. 

Depending on the situation, there are arguments to go ahead with A/B testing before and after developing a GUI. If there are resources to do both, the recommendation is to develop the GUI first. Having a GUI potentially makes the learning curve smaller and thereby gets less spread on the results. If there only is resources to do the tests or the GUI, the argument could be made to do the tests first. In the worst case, this would give indications on the efficiency of the tool and at best statistically establish the tool as efficient. Then the question becomes easier if there is an opportunity to invest in the tool. 
